{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import wandb\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset,DatasetDict\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model_state_dict\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[3;92mTrue\u001b[0m"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rich import (inspect, print, pretty)\n",
    "from rich.console import Console\n",
    "from rich.syntax import Syntax\n",
    "pretty.install()\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class CustomInvoiceDataset(Dataset):\n",
    "    def __init__(self, json_folder, text_folder):\n",
    "        self.text_files = [os.path.join(text_folder, file) for file in os.listdir(text_folder)]\n",
    "        self.json_files = [os.path.join(json_folder, file) for file in os.listdir(json_folder)]\n",
    "        self.text_files.sort()\n",
    "        self.json_files.sort()\n",
    "\n",
    "        assert len(self.text_files) == len(self.json_files), \"Mismatch in number of files\"\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        with open(self.text_files[index],'r') as file:\n",
    "            text_content = file.read()\n",
    "            lines  = text_content.splitlines()\n",
    "            list_of_lists = [ast.literal_eval(line) for line in lines]\n",
    "\n",
    "        with open(self.json_files[index], 'r') as file:\n",
    "            json_content = json.load(file)\n",
    "        return list_of_lists, str(json_content)\n",
    "    @property\n",
    "    def features(self):\n",
    "        return ('text','json')\n",
    "    @property\n",
    "    def num_rows(self):\n",
    "        return len(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomInvoiceDataset(\"/home/huynv43/langchain_rag/data/json\", \"/home/huynv43/langchain_rag/data/txt_dataset_with_coor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">453</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m453\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "total_size = len(data)\n",
    "print(total_size)\n",
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "train_size = int(total_size * train_ratio)\n",
    "valid_size = int(total_size * valid_ratio)\n",
    "test_size = total_size - train_size - valid_size \n",
    "train_dataset, valid_dataset, test_dataset = random_split(data, [train_size, valid_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_train_instruction(sample):\n",
    "    return f\"\"\"### Instruction:\n",
    "You are medical expert, and medical data engineer with many years on working with complex medical receipt structure. \n",
    "I need you parse, detect, recognize and convert following medical receipt OCR image result into structure medical receipt format. \n",
    "the outout mus be a well-formed json object.```json\n",
    "\n",
    "### Input:\n",
    "{sample[0]}\n",
    "\n",
    "### Output:\n",
    "{sample[1]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction:\n",
       "You are medical expert, and medical data engineer with many years on working with complex medical receipt \n",
       "structure. \n",
       "I need you parse, detect, recognize and convert following medical receipt OCR image result into structure medical \n",
       "receipt format. \n",
       "the outout mus be a well-formed json object.```json\n",
       "\n",
       "### Input:\n",
       "<span style=\"font-weight: bold\">[[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">616</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">805</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">805</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">616</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'BỘ Y TẾ'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">334</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1040</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">166</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1040</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">334</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'BỆNH VIỆN NHI TRUNG ƯƠNG'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">289</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">289</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Khoa KB:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">541</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">245</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">541</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">292</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'PKTN_S1_104'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1542</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">282</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Mã Y </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Tế:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1551</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1747</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1747</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">278</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1551</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">278</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'220501401'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">728</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">353</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1122</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">353</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1122</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">412</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">728</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">412</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ĐƠN THUỐC'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">444</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">241</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">483</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">483</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Mã đơn:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">446</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">446</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">512</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">484</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">484</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'01915clG6492-C'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">324</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">324</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Họ và tên:'</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">493</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">555</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'LÊ NGỌC BẢO ANH'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1292</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">498</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1485</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">498</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1485</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">542</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1292</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">542</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Giới tính:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1497</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">497</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">497</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1497</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Nữ'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">573</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">220</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">573</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">220</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">622</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Tuổi:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">578</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">427</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">233</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'35 Tháng'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">887</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">568</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">887</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">619</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">666</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">619</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày sinh:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1129</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1129</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">610</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">905</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">610</span><span style=\"font-weight: bold\">)]</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'31/12/2019'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1292</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">571</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1495</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1292</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Cân nặng:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1513</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">562</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1705</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">562</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1705</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1513</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">618</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'16.00 kg'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">651</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Địa Chỉ:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">632</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">632</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1269</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">702</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">702</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Phường Phú Thượng, Quận Tây Hồ, TP Hà Nội'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">117</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">719</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">344</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">719</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">344</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">766</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">117</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">766</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Chẩn đoán:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">359</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">709</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1094</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">709</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1094</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">765</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">359</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">765</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Viêm mũi họng </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">loạn tiêu hóa'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">792</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">406</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">792</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">406</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">841</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">841</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Bệnh kèm theo:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">851</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">851</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">518</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">907</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">907</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Thuốc điều tri:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">835</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1625</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">835</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1625</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">896</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1419</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">896</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Số lương'</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">918</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">918</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">674</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">971</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">116</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">971</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'1/ Cefprozil (Cefdiri 250mg)'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">913</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1558</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">913</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1558</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">971</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">971</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'14 gói'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1033</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1033</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày Uống 2 gói chia 2 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lần'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1041</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1320</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1041</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1320</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1102</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1102</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'2/ Hỗn hợp dịch chiết, tinh dầu, mật ong (Fortuss </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cough syrup'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1048</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1534</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1048</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1534</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1101</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1423</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1101</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'01 lọ'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1116</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">251</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1116</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">251</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1164</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1164</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'180ml)'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1160</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1160</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">640</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1224</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1224</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày uống 12 ml chia </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">3 lần'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1220</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1541</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1220</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1541</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1286</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1286</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'3/ Cây giao (san hô xanh), Tao giác thích (gai </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">bồ kết), Thương nhĩ tử 01 lọ'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1296</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">802</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1296</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">802</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1349</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">112</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1349</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'(Xịt mũi Matara Baby Nose </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">20ml)'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1346</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">777</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1346</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">777</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1410</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1410</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Xịt mũi ngày 2 lần, mỗi lần 2 nhát'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1417</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1221</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1417</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1221</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1470</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1470</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'4/ bacillus subtilis+L.acidophlus (Pro-Acido) Plus 100g)'</span><span style=\"font-weight: bold\">]</span>, \n",
       "<span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1429</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1415</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1543</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1415</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1543</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1471</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1429</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1471</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'01 lọ'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1474</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1474</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">869</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>,\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1537</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày uống 2 thìa chia 2 lần sáng, chiều'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1556</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1556</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1232</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1608</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'5/ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Men vi sinh+Simethicone (Comil 40mg/20 giọt 20ml)'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1429</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1553</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1590</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1553</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1590</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1603</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1429</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1603</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'01</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chai'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1614</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1614</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">754</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1672</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">114</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1672</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày uống 2 ml chia 2 lần sau ăn'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1687</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1687</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">249</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ghi chú:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1679</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1466</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1679</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1466</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1736</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1736</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'NÊU </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ĐAU NHIÊU, SỐT, NÔN DỊCH VÀNG ĐI KHÁM CẤP CỨU.'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">594</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1734</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">594</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1798</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1798</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'* Thuốc </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ngoài danh mục:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2059</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2059</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2112</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2112</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Cộng khoản:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">374</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2063</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">526</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2063</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">526</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2109</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">374</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2109</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'5 khoản'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2058</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1733</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2058</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1733</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1109</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2119</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Ngày 07 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tháng 12 năm 2022'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1215</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2118</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1603</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2118</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1603</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2171</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1215</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2171</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Bác bệnh'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2251</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">829</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2251</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">829</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2309</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2309</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'*Nếu bất thường đến cơ sở ytế gần nhất.'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2309</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">370</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2309</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">370</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2361</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2361</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'* Khám lại sau'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2366</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2366</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">724</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2420</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2420</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'* Khám lại xin mang </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">theo đơn này.'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2418</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">968</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2418</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">968</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2478</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2478</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'*Họ tên bố hoặc mẹ nếu BN dưới 72 tháng </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tuổi:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2432</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1481</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2432</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1481</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2523</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2523</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'PHẠM NGỌC ANH-ĐT:'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1485</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2475</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1711</span>, \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2475</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1711</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2521</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1485</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2521</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'0988085888'</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[[(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1320</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2399</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1579</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2399</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1579</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2456</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1320</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2456</span><span style=\"font-weight: bold\">)]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Đỗ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Văn Đô'</span><span style=\"font-weight: bold\">]]</span>\n",
       "\n",
       "### Output:\n",
       "<span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"patient_info\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"current_institute\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"BỆNH VIỆN NHI TRUNG ƯƠNG\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"LÊ NGỌC BẢO ANH\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"gender\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Nữ\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"birth\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"31/12/2019\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"age\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"35 Tháng\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"address\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Phường Phú Thượng, Quận Tây Hồ, TP Hà Nội\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"id_bhyt\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"220501401\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"medical_info\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"diagnosis\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Viêm mũi họng loạn tiêu hóa\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"date_in\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"07 tháng 12 năm 2022\"</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"doctor_name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"prescription_info\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">\"medications\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Cefprozil (Cefdiri 250mg)\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"dosage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"morning\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 gói\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"evening\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 gói\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"quantity\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"14 gói\"</span>\n",
       "\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Hỗn hợp dịch chiết, tinh dầu, mật ong (Fortuss cough syrup 180ml)\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"dosage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"morning\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"12 ml\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"evening\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"12 ml\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"quantity\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"01 lọ\"</span>\n",
       "\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Cây giao (san hô xanh), Tao giác thích (gai bồ kết), Thương nhĩ tử (Xịt mũi Matara Baby </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Nose 20ml)\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"dosage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"morning\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 nhát\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"evening\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 nhát\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"quantity\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"01 lọ\"</span>\n",
       "\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"bacillus subtilis+L.acidophlus (Pro-Acido) Plus 100g)\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"dosage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"morning\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 thìa\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"evening\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 thìa\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"quantity\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"01 lọ\"</span>\n",
       "\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"name\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Men vi sinh+Simethicone (Comil 40mg/20 giọt 20ml)\"</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"dosage\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"morning\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 ml\"</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">\"evening\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2 ml\"</span>\n",
       "                <span style=\"font-weight: bold\">}</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">\"quantity\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"01 chai\"</span>\n",
       "\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction:\n",
       "You are medical expert, and medical data engineer with many years on working with complex medical receipt \n",
       "structure. \n",
       "I need you parse, detect, recognize and convert following medical receipt OCR image result into structure medical \n",
       "receipt format. \n",
       "the outout mus be a well-formed json object.```json\n",
       "\n",
       "### Input:\n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m616\u001b[0m, \u001b[1;36m111\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m805\u001b[0m, \u001b[1;36m111\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m805\u001b[0m, \u001b[1;36m165\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m616\u001b[0m, \u001b[1;36m165\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'BỘ Y TẾ'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m334\u001b[0m, \u001b[1;36m166\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1040\u001b[0m, \u001b[1;36m166\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1040\u001b[0m, \u001b[1;36m226\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m334\u001b[0m, \n",
       "\u001b[1;36m226\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'BỆNH VIỆN NHI TRUNG ƯƠNG'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m340\u001b[0m, \u001b[1;36m245\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m533\u001b[0m, \u001b[1;36m245\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m533\u001b[0m, \u001b[1;36m289\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m340\u001b[0m, \u001b[1;36m289\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Khoa KB:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m541\u001b[0m, \u001b[1;36m245\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m834\u001b[0m, \u001b[1;36m245\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m834\u001b[0m, \u001b[1;36m292\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m541\u001b[0m, \u001b[1;36m292\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'PKTN_S1_104'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1372\u001b[0m, \u001b[1;36m233\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1542\u001b[0m, \u001b[1;36m233\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1542\u001b[0m, \u001b[1;36m282\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1372\u001b[0m, \u001b[1;36m282\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Mã Y \u001b[0m\n",
       "\u001b[32mTế:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1551\u001b[0m, \u001b[1;36m240\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1747\u001b[0m, \u001b[1;36m240\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1747\u001b[0m, \u001b[1;36m278\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1551\u001b[0m, \u001b[1;36m278\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'220501401'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m728\u001b[0m, \u001b[1;36m353\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1122\u001b[0m, \u001b[1;36m353\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1122\u001b[0m, \u001b[1;36m412\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m728\u001b[0m, \u001b[1;36m412\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'ĐƠN THUỐC'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m444\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m241\u001b[0m, \u001b[1;36m444\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m241\u001b[0m, \u001b[1;36m483\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m483\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Mã đơn:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m252\u001b[0m, \u001b[1;36m446\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m446\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[1m(\u001b[0m\u001b[1;36m512\u001b[0m, \u001b[1;36m484\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m252\u001b[0m, \u001b[1;36m484\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'01915clG6492-C'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m502\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m, \u001b[1;36m502\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m324\u001b[0m, \u001b[1;36m555\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m555\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Họ và tên:'\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m333\u001b[0m, \u001b[1;36m493\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m810\u001b[0m, \u001b[1;36m493\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m810\u001b[0m, \u001b[1;36m555\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m333\u001b[0m, \u001b[1;36m555\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'LÊ NGỌC BẢO ANH'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1292\u001b[0m, \u001b[1;36m498\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1485\u001b[0m, \u001b[1;36m498\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1485\u001b[0m, \u001b[1;36m542\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1292\u001b[0m, \u001b[1;36m542\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Giới tính:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1497\u001b[0m, \u001b[1;36m497\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1571\u001b[0m, \u001b[1;36m497\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1571\u001b[0m, \u001b[1;36m539\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1497\u001b[0m, \u001b[1;36m539\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Nữ'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m116\u001b[0m, \u001b[1;36m573\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m220\u001b[0m, \n",
       "\u001b[1;36m573\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m220\u001b[0m, \u001b[1;36m622\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m116\u001b[0m, \u001b[1;36m622\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Tuổi:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m233\u001b[0m, \u001b[1;36m578\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m427\u001b[0m, \u001b[1;36m578\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m427\u001b[0m, \u001b[1;36m629\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m233\u001b[0m, \u001b[1;36m629\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'35 Tháng'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m666\u001b[0m, \n",
       "\u001b[1;36m568\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m887\u001b[0m, \u001b[1;36m568\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m887\u001b[0m, \u001b[1;36m619\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m666\u001b[0m, \u001b[1;36m619\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày sinh:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m905\u001b[0m, \u001b[1;36m571\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1129\u001b[0m, \u001b[1;36m571\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1129\u001b[0m, \u001b[1;36m610\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m905\u001b[0m, \u001b[1;36m610\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[32m'31/12/2019'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1292\u001b[0m, \u001b[1;36m571\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1495\u001b[0m, \u001b[1;36m571\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1495\u001b[0m, \u001b[1;36m618\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1292\u001b[0m, \u001b[1;36m618\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Cân nặng:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1513\u001b[0m, \u001b[1;36m562\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1705\u001b[0m, \u001b[1;36m562\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1705\u001b[0m, \u001b[1;36m618\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1513\u001b[0m, \u001b[1;36m618\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'16.00 kg'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m651\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m287\u001b[0m, \u001b[1;36m651\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m287\u001b[0m, \u001b[1;36m700\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m700\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Địa Chỉ:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m300\u001b[0m, \n",
       "\u001b[1;36m632\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1269\u001b[0m, \u001b[1;36m632\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1269\u001b[0m, \u001b[1;36m702\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m300\u001b[0m, \u001b[1;36m702\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Phường Phú Thượng, Quận Tây Hồ, TP Hà Nội'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m117\u001b[0m, \u001b[1;36m719\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m344\u001b[0m, \n",
       "\u001b[1;36m719\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m344\u001b[0m, \u001b[1;36m766\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m117\u001b[0m, \u001b[1;36m766\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Chẩn đoán:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m359\u001b[0m, \u001b[1;36m709\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1094\u001b[0m, \u001b[1;36m709\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1094\u001b[0m, \u001b[1;36m765\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m359\u001b[0m, \u001b[1;36m765\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Viêm mũi họng \u001b[0m\n",
       "\u001b[32mloạn tiêu hóa'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m792\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m406\u001b[0m, \u001b[1;36m792\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m406\u001b[0m, \u001b[1;36m841\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m841\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Bệnh kèm theo:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m190\u001b[0m, \u001b[1;36m851\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m518\u001b[0m, \u001b[1;36m851\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m518\u001b[0m, \u001b[1;36m907\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m190\u001b[0m, \u001b[1;36m907\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Thuốc điều tri:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1419\u001b[0m, \u001b[1;36m835\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1625\u001b[0m, \u001b[1;36m835\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1625\u001b[0m, \u001b[1;36m896\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1419\u001b[0m, \u001b[1;36m896\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Số lương'\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m116\u001b[0m, \u001b[1;36m918\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m674\u001b[0m, \u001b[1;36m918\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m674\u001b[0m, \u001b[1;36m971\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m116\u001b[0m, \u001b[1;36m971\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'1/ Cefprozil \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCefdiri 250mg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1423\u001b[0m, \u001b[1;36m913\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1558\u001b[0m, \u001b[1;36m913\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m1558\u001b[0m, \u001b[1;36m971\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1423\u001b[0m, \u001b[1;36m971\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'14 gói'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m119\u001b[0m, \u001b[1;36m967\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m640\u001b[0m, \u001b[1;36m967\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m640\u001b[0m, \u001b[1;36m1033\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m119\u001b[0m, \u001b[1;36m1033\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày Uống 2 gói chia 2 \u001b[0m\n",
       "\u001b[32mlần'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m1041\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1320\u001b[0m, \u001b[1;36m1041\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1320\u001b[0m, \u001b[1;36m1102\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m1102\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'2/ Hỗn hợp dịch chiết, tinh dầu, mật ong \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFortuss \u001b[0m\n",
       "\u001b[32mcough syrup'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1423\u001b[0m, \u001b[1;36m1048\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1534\u001b[0m, \u001b[1;36m1048\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1534\u001b[0m, \u001b[1;36m1101\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1423\u001b[0m, \u001b[1;36m1101\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'01 lọ'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m1116\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m251\u001b[0m, \u001b[1;36m1116\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m251\u001b[0m, \u001b[1;36m1164\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m1164\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'180ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m1160\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m640\u001b[0m, \u001b[1;36m1160\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m640\u001b[0m, \u001b[1;36m1224\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m1224\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày uống 12 ml chia \u001b[0m\n",
       "\u001b[32m3 lần'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1220\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1541\u001b[0m, \u001b[1;36m1220\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1541\u001b[0m, \u001b[1;36m1286\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1286\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'3/ Cây giao \u001b[0m\u001b[32m(\u001b[0m\u001b[32msan hô xanh\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Tao giác thích \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgai \u001b[0m\n",
       "\u001b[32mbồ kết\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Thương nhĩ tử 01 lọ'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m1296\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m802\u001b[0m, \u001b[1;36m1296\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m802\u001b[0m, \u001b[1;36m1349\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m112\u001b[0m, \u001b[1;36m1349\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'\u001b[0m\u001b[32m(\u001b[0m\u001b[32mXịt mũi Matara Baby Nose \u001b[0m\n",
       "\u001b[32m20ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m1346\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m777\u001b[0m, \u001b[1;36m1346\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m777\u001b[0m, \u001b[1;36m1410\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m109\u001b[0m, \u001b[1;36m1410\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Xịt mũi ngày 2 lần, mỗi lần 2 nhát'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \n",
       "\u001b[1;36m1417\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1221\u001b[0m, \u001b[1;36m1417\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1221\u001b[0m, \u001b[1;36m1470\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1470\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'4/ bacillus subtilis+L.acidophlus \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPro-Acido\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Plus 100g\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \n",
       "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1429\u001b[0m, \u001b[1;36m1415\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1543\u001b[0m, \u001b[1;36m1415\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1543\u001b[0m, \u001b[1;36m1471\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1429\u001b[0m, \u001b[1;36m1471\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'01 lọ'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m110\u001b[0m, \u001b[1;36m1474\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m869\u001b[0m, \u001b[1;36m1474\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m869\u001b[0m, \u001b[1;36m1537\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m110\u001b[0m,\n",
       "\u001b[1;36m1537\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày uống 2 thìa chia 2 lần sáng, chiều'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1556\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1232\u001b[0m, \u001b[1;36m1556\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1232\u001b[0m, \u001b[1;36m1608\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1608\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'5/ \u001b[0m\n",
       "\u001b[32mMen vi sinh+Simethicone \u001b[0m\u001b[32m(\u001b[0m\u001b[32mComil 40mg/20 giọt 20ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1429\u001b[0m, \u001b[1;36m1553\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1590\u001b[0m, \u001b[1;36m1553\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1590\u001b[0m, \u001b[1;36m1603\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1429\u001b[0m, \u001b[1;36m1603\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'01\u001b[0m\n",
       "\u001b[32mchai'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m1614\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m754\u001b[0m, \u001b[1;36m1614\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m754\u001b[0m, \u001b[1;36m1672\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m114\u001b[0m, \u001b[1;36m1672\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày uống 2 ml chia 2 lần sau ăn'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m1687\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1m(\u001b[0m\u001b[1;36m249\u001b[0m, \u001b[1;36m1687\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m249\u001b[0m, \u001b[1;36m1734\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m1734\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ghi chú:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m258\u001b[0m, \u001b[1;36m1679\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1466\u001b[0m, \u001b[1;36m1679\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1466\u001b[0m, \u001b[1;36m1736\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m258\u001b[0m, \u001b[1;36m1736\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'NÊU \u001b[0m\n",
       "\u001b[32mĐAU NHIÊU, SỐT, NÔN DỊCH VÀNG ĐI KHÁM CẤP CỨU.'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1734\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m594\u001b[0m, \u001b[1;36m1734\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m594\u001b[0m, \u001b[1;36m1798\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m107\u001b[0m, \u001b[1;36m1798\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'* Thuốc \u001b[0m\n",
       "\u001b[32mngoài danh mục:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m2059\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m369\u001b[0m, \u001b[1;36m2059\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m369\u001b[0m, \u001b[1;36m2112\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m2112\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Cộng khoản:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m374\u001b[0m, \u001b[1;36m2063\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m526\u001b[0m, \n",
       "\u001b[1;36m2063\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m526\u001b[0m, \u001b[1;36m2109\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m374\u001b[0m, \u001b[1;36m2109\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'5 khoản'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1109\u001b[0m, \u001b[1;36m2058\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1733\u001b[0m, \u001b[1;36m2058\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1733\u001b[0m, \u001b[1;36m2119\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1109\u001b[0m, \u001b[1;36m2119\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Ngày 07 \u001b[0m\n",
       "\u001b[32mtháng 12 năm 2022'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1215\u001b[0m, \u001b[1;36m2118\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1603\u001b[0m, \u001b[1;36m2118\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1603\u001b[0m, \u001b[1;36m2171\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1215\u001b[0m, \u001b[1;36m2171\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Bác bệnh'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m2251\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m829\u001b[0m, \n",
       "\u001b[1;36m2251\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m829\u001b[0m, \u001b[1;36m2309\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m2309\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'*Nếu bất thường đến cơ sở ytế gần nhất.'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m2309\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m370\u001b[0m, \u001b[1;36m2309\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m370\u001b[0m, \n",
       "\u001b[1;36m2361\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m99\u001b[0m, \u001b[1;36m2361\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'* Khám lại sau'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2366\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m724\u001b[0m, \u001b[1;36m2366\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m724\u001b[0m, \u001b[1;36m2420\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2420\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'* Khám lại xin mang \u001b[0m\n",
       "\u001b[32mtheo đơn này.'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m2418\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m968\u001b[0m, \u001b[1;36m2418\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m968\u001b[0m, \u001b[1;36m2478\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m101\u001b[0m, \u001b[1;36m2478\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'*Họ tên bố hoặc mẹ nếu BN dưới 72 tháng \u001b[0m\n",
       "\u001b[32mtuổi:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m972\u001b[0m, \u001b[1;36m2432\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1481\u001b[0m, \u001b[1;36m2432\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1481\u001b[0m, \u001b[1;36m2523\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m972\u001b[0m, \u001b[1;36m2523\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'PHẠM NGỌC ANH-ĐT:'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1485\u001b[0m, \u001b[1;36m2475\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1711\u001b[0m, \n",
       "\u001b[1;36m2475\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1711\u001b[0m, \u001b[1;36m2521\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1485\u001b[0m, \u001b[1;36m2521\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'0988085888'\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1320\u001b[0m, \u001b[1;36m2399\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1579\u001b[0m, \u001b[1;36m2399\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1579\u001b[0m, \u001b[1;36m2456\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[1;36m1320\u001b[0m, \u001b[1;36m2456\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'Đỗ \u001b[0m\n",
       "\u001b[32mVăn Đô'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n",
       "\n",
       "### Output:\n",
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"patient_info\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"current_institute\"\u001b[0m: \u001b[32m\"BỆNH VIỆN NHI TRUNG ƯƠNG\"\u001b[0m,\n",
       "        \u001b[32m\"name\"\u001b[0m: \u001b[32m\"LÊ NGỌC BẢO ANH\"\u001b[0m,\n",
       "        \u001b[32m\"gender\"\u001b[0m: \u001b[32m\"Nữ\"\u001b[0m,\n",
       "        \u001b[32m\"birth\"\u001b[0m: \u001b[32m\"31/12/2019\"\u001b[0m,\n",
       "        \u001b[32m\"age\"\u001b[0m: \u001b[32m\"35 Tháng\"\u001b[0m,\n",
       "        \u001b[32m\"address\"\u001b[0m: \u001b[32m\"Phường Phú Thượng, Quận Tây Hồ, TP Hà Nội\"\u001b[0m,\n",
       "        \u001b[32m\"id_bhyt\"\u001b[0m: \u001b[32m\"220501401\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m\"medical_info\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"diagnosis\"\u001b[0m: \u001b[32m\"Viêm mũi họng loạn tiêu hóa\"\u001b[0m,\n",
       "        \u001b[32m\"date_in\"\u001b[0m: \u001b[32m\"07 tháng 12 năm 2022\"\u001b[0m,\n",
       "        \u001b[32m\"doctor_name\"\u001b[0m: \u001b[32m\"\"\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m\"prescription_info\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m\"medications\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"name\"\u001b[0m: \u001b[32m\"Cefprozil \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCefdiri 250mg\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                \u001b[32m\"dosage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"morning\"\u001b[0m: \u001b[32m\"2 gói\"\u001b[0m,\n",
       "                    \u001b[32m\"evening\"\u001b[0m: \u001b[32m\"2 gói\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"quantity\"\u001b[0m: \u001b[32m\"14 gói\"\u001b[0m\n",
       "\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"name\"\u001b[0m: \u001b[32m\"Hỗn hợp dịch chiết, tinh dầu, mật ong \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFortuss cough syrup 180ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                \u001b[32m\"dosage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"morning\"\u001b[0m: \u001b[32m\"12 ml\"\u001b[0m,\n",
       "                    \u001b[32m\"evening\"\u001b[0m: \u001b[32m\"12 ml\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"quantity\"\u001b[0m: \u001b[32m\"01 lọ\"\u001b[0m\n",
       "\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"name\"\u001b[0m: \u001b[32m\"Cây giao \u001b[0m\u001b[32m(\u001b[0m\u001b[32msan hô xanh\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Tao giác thích \u001b[0m\u001b[32m(\u001b[0m\u001b[32mgai bồ kết\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Thương nhĩ tử \u001b[0m\u001b[32m(\u001b[0m\u001b[32mXịt mũi Matara Baby \u001b[0m\n",
       "\u001b[32mNose 20ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                \u001b[32m\"dosage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"morning\"\u001b[0m: \u001b[32m\"2 nhát\"\u001b[0m,\n",
       "                    \u001b[32m\"evening\"\u001b[0m: \u001b[32m\"2 nhát\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"quantity\"\u001b[0m: \u001b[32m\"01 lọ\"\u001b[0m\n",
       "\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"name\"\u001b[0m: \u001b[32m\"bacillus subtilis+L.acidophlus \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPro-Acido\u001b[0m\u001b[32m)\u001b[0m\u001b[32m Plus 100g\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                \u001b[32m\"dosage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"morning\"\u001b[0m: \u001b[32m\"2 thìa\"\u001b[0m,\n",
       "                    \u001b[32m\"evening\"\u001b[0m: \u001b[32m\"2 thìa\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"quantity\"\u001b[0m: \u001b[32m\"01 lọ\"\u001b[0m\n",
       "\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[1m{\u001b[0m\n",
       "                \u001b[32m\"name\"\u001b[0m: \u001b[32m\"Men vi sinh+Simethicone \u001b[0m\u001b[32m(\u001b[0m\u001b[32mComil 40mg/20 giọt 20ml\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m,\n",
       "                \u001b[32m\"dosage\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                    \u001b[32m\"morning\"\u001b[0m: \u001b[32m\"2 ml\"\u001b[0m,\n",
       "                    \u001b[32m\"evening\"\u001b[0m: \u001b[32m\"2 ml\"\u001b[0m\n",
       "                \u001b[1m}\u001b[0m,\n",
       "                \u001b[32m\"quantity\"\u001b[0m: \u001b[32m\"01 chai\"\u001b[0m\n",
       "\n",
       "            \u001b[1m}\u001b[0m\n",
       "        \u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import randrange\n",
    "print(format_train_instruction(train_dataset[randrange(len(train_dataset))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_token_ratio(dataset, tokenizer, nb_examples=400):\n",
    "    \"\"\"\n",
    "    Estimate the average number of characters per token in the dataset.\n",
    "    \"\"\"\n",
    "    total_characters, total_tokens = 0, 0\n",
    "    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n",
    "        text = format_train_instruction(example)\n",
    "        total_characters += len(text)\n",
    "        if tokenizer.is_fast:\n",
    "            total_tokens += len(tokenizer(text).tokens())\n",
    "        else:\n",
    "            total_tokens += len(tokenizer.tokenize(text))\n",
    "\n",
    "    return total_characters / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_datasets(tokenizer,train_data, test_data, valid_data ,data_dir=None,seq_length=2048,num_workers=6,streaming=False,size_valid_set=10,shuffle_buffer=1000):\n",
    "    train_data = train_data\n",
    "    valid_data = valid_data\n",
    "    chars_per_token = chars_token_ratio(train_data, tokenizer)\n",
    "    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        formatting_func=format_train_instruction,\n",
    "        infinite=True,\n",
    "        seq_length=seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        valid_data,\n",
    "        formatting_func=format_train_instruction,\n",
    "        infinite=False,\n",
    "        seq_length=seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    return train_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "hf_token = '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'\n",
    "\n",
    "use_flash_attention = False\n",
    "# Hugging Face model id\n",
    "#model_id = \"NousResearch/Llama-2-7b-hf\" # non-gated \"meta-llama/Llama-2-7b-hf\n",
    "#model_id=\"PY007/TinyLlama-1.1B-intermediate-step-240k-503b\"\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\" \n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "##quantization_config=bnb_config, \n",
    "# Load model and tokenizer\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(model_id, \n",
    "                                             #load_in_8bit=True,      \n",
    "                                             quantization_config=bnb_config,  \n",
    "                                             token = hf_token,\n",
    "                                             trust_remote_code=True,                                                  \n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model_8bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frezee the model\n",
    "for param in model_8bit.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model_8bit.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "model_8bit.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model_8bit.lm_head = CastOutputToFloat(model_8bit.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8bit.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_8bit.get_memory_footprint()/1024/1024/1024, \"GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_8bit.config.max_position_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8bit.hf_device_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=64, \n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"], # skip this time\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "## prepare model for training\n",
    "model = prepare_model_for_kbit_training(model_8bit)\n",
    "base_model = get_peft_model(model, peft_config)\n",
    "base_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"] = \"Medical-kie\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "OUTPUT_DIR = \"./results/mistral7b_ocr_to_json_5_without_torch\"\n",
    "NUM_TRAIN_EPOCHS = 5\n",
    "BATCH_SIZE=128\n",
    "PER_DEVICE_TRAIN_BATCH_SIZE=3\n",
    "PER_DEVICE_EVAL_BATCH_SIZE=1\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // PER_DEVICE_TRAIN_BATCH_SIZE\n",
    "SAVE_STEPS=20\n",
    "LOGGING_STEPS=10\n",
    "LEARNING_RATE=2e-4 #3e-4\n",
    "TRAIN_STEPS=150  #300\n",
    "#WARM_UP_STEPS=50  or ratio \n",
    "max_seq_length = 2048 # max sequence length for model and packing of the dataset\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=PER_DEVICE_TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH_SIZE,        \n",
    "    gradient_accumulation_steps=2, ## GRADIENT_ACCUMULATION_STEPS,\n",
    "    gradient_checkpointing=True,        \n",
    "    optim=\"paged_adamw_32bit\",  \n",
    "    logging_steps=LOGGING_STEPS,    \n",
    "    save_total_limit=2,  \n",
    "    save_strategy=\"epoch\",    \n",
    "    learning_rate=2e-4,            ## LEARNING_RATE,    \n",
    "    fp16=True,\n",
    "    # tf32=True,        \n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,             ## warmup_steps=WARM_UP_STEPS,    \n",
    "    lr_scheduler_type=\"constant\",  ##\"cosine\"   \n",
    "    disable_tqdm=True,              # disable tqdm since with packing values are in correct    \n",
    "    #max_steps=TRAIN_STEPS,\n",
    "    report_to=\"wandb\",\n",
    "    #save_steps=SAVE_STEPS,\n",
    "    #group_by_length=False,\n",
    "    #remove_unused_columns=False,\n",
    "    evaluation_strategy=\"epoch\",  #steps\n",
    "    run_name=\"sft_mistral7b_colorist\",\n",
    "\n",
    ")\n",
    "train_dataset, eval_dataset = create_datasets(base_tokenizer, train_dataset, test_dataset, valid_dataset, seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer,DataCollatorForCompletionOnlyLM\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_config,\n",
    "    packing=True,  ## make sure group_by_length=False\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=base_tokenizer,\n",
    "    args=training_args,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.pretraining_tp = 1\n",
    "base_model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "\n",
    "## pytorch optimization \n",
    "old_state_dict = base_model.state_dict\n",
    "base_model.state_dict = (\n",
    "    lambda self, *_, **__: get_peft_model_state_dict(\n",
    "        self, old_state_dict()\n",
    "    )\n",
    ").__get__(base_model, type(base_model)) \n",
    "\n",
    "# Enable cuDNN auto-tuner - NVIDIA cuDNN supports many algorithms to compute a convolution. \n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train() # there will not be a progress bar since tqdm is disabled\n",
    "# save model\n",
    "trainer.save_model(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(OUTPUT_DIR, \"final_checkpoint\")\n",
    "trainer.model.save_pretrained(output_dir)\n",
    "base_tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.push_to_hub(\"nguyenhuy/mistral7b_ocr_to_json-lora\", token = \"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del base_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "output_dir=\"/home/huynv43/langchain_rag/sft_mistral/results/mistral7b_ocr_to_json_5_without_torch/final_checkpoint\"\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "peft_model_id = output_dir\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "print(config.base_model_name_or_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                                 # return_dict=True,\n",
    "                                                 # load_in_4bit=True,                                                 \n",
    "                                                 device_map=\"auto\",\n",
    "                                                 trust_remote_code=True,  \n",
    "                                                 low_cpu_mem_usage=True,                                                \n",
    "                                                 torch_dtype=torch.bfloat16\n",
    "                                                )\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id,trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=\"/home/huynv43/langchain_rag/sft_mistral/results/mistral7b_ocr_to_json_5_without_torch/final_checkpoint\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig, AutoPeftModelForCausalLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map = \"auto\", local_files_only=True, \n",
    "    load_in_4bit=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_confi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def generate_and_tokenize_prompt(sample):\n",
    "    return tokenizer(format_train_instruction(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_dataset =  list(train_dataset)\n",
    "list_val_dataset = list(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = create_datasets(tokenizer, train_dataset, test_dataset, valid_dataset, seq_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = accelerator.prepare_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project = \"journal-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"journal-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.64s/it]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_train_instruction(sample):\n",
    "    return f\"\"\"### Instruction:\n",
    "You are medical expert, and medical data engineer with many years on working with complex medical receipt structure. \n",
    "I need you parse, detect, recognize and convert following medical receipt OCR image result into structure medical receipt format. \n",
    "the outout mus be a well-formed json object.```json\n",
    "\n",
    "### Input:\n",
    "{sample[0]}\n",
    "\n",
    "### Output:\n",
    "{sample[1]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.map(lambda samples: format_train_instruction(samples), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralForCausalLM</span><span style=\"font-weight: bold\">(</span>\n",
       "  <span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralModel</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"font-weight: bold\">(</span>embed_tokens<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>layers<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
       "      <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">31</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralDecoderLayer</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"font-weight: bold\">(</span>self_attn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralAttention</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>q_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>k_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>v_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>o_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>rotary_emb<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralRotaryEmbedding</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>mlp<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralMLP</span><span style=\"font-weight: bold\">(</span>\n",
       "          <span style=\"font-weight: bold\">(</span>gate_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14336</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>up_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14336</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>down_proj<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear4bit</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14336</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "          <span style=\"font-weight: bold\">(</span>act_fn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SiLU</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">(</span>input_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "        <span style=\"font-weight: bold\">(</span>post_attention_layernorm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "      <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">(</span>norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MistralRMSNorm</span><span style=\"font-weight: bold\">()</span>\n",
       "  <span style=\"font-weight: bold\">)</span>\n",
       "  <span style=\"font-weight: bold\">(</span>lm_head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32000</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mMistralForCausalLM\u001b[0m\u001b[1m(\u001b[0m\n",
       "  \u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m: \u001b[1;35mMistralModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1m(\u001b[0membed_tokens\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m32000\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mlayers\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
       "      \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m31\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m32\u001b[0m x \u001b[1;35mMistralDecoderLayer\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[1m(\u001b[0mself_attn\u001b[1m)\u001b[0m: \u001b[1;35mMistralAttention\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mq_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mk_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mv_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m1024\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mo_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mrotary_emb\u001b[1m)\u001b[0m: \u001b[1;35mMistralRotaryEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mmlp\u001b[1m)\u001b[0m: \u001b[1;35mMistralMLP\u001b[0m\u001b[1m(\u001b[0m\n",
       "          \u001b[1m(\u001b[0mgate_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m14336\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mup_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m14336\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mdown_proj\u001b[1m)\u001b[0m: \u001b[1;35mLinear4bit\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m14336\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "          \u001b[1m(\u001b[0mact_fn\u001b[1m)\u001b[0m: \u001b[1;35mSiLU\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0minput_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mMistralRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m(\u001b[0mpost_attention_layernorm\u001b[1m)\u001b[0m: \u001b[1;35mMistralRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "      \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "    \u001b[1m(\u001b[0mnorm\u001b[1m)\u001b[0m: \u001b[1;35mMistralRMSNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "  \u001b[1m)\u001b[0m\n",
       "  \u001b[1m(\u001b[0mlm_head\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m4096\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m32000\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "      lora_module_names.remove('lm_head')\n",
    "  return list(lora_module_names)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'o_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'up_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'down_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gate_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'q_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'v_proj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'k_proj'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[32m'o_proj'\u001b[0m, \u001b[32m'up_proj'\u001b[0m, \u001b[32m'down_proj'\u001b[0m, \u001b[32m'gate_proj'\u001b[0m, \u001b[32m'q_proj'\u001b[0m, \u001b[32m'v_proj'\u001b[0m, \u001b[32m'k_proj'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Trainable: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20971520</span> | total: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7262703616</span> | Percentage: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2888</span>%\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Trainable: \u001b[1;36m20971520\u001b[0m | total: \u001b[1;36m7262703616\u001b[0m | Percentage: \u001b[1;36m0.2888\u001b[0m%\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:222: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:282: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=0.03,\n",
    "        max_steps=100,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        save_strategy=\"epoch\",\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/huynv43/langchain_rag/sft_mistral/wandb/run-20240110_123514-8wzkv9rw</code>"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vinhhuyqna/huggingface/runs/8wzkv9rw' target=\"_blank\">earthy-fire-1</a></strong> to <a href='https://wandb.ai/vinhhuyqna/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vinhhuyqna/huggingface' target=\"_blank\">https://wandb.ai/vinhhuyqna/huggingface</a>"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vinhhuyqna/huggingface/runs/8wzkv9rw' target=\"_blank\">https://wandb.ai/vinhhuyqna/huggingface/runs/8wzkv9rw</a>"
      ],
      "text/plain": [
       "\u001b[1m<\u001b[0m\u001b[1;95mIPython.core.display.HTML\u001b[0m\u001b[39m object\u001b[0m\u001b[1m>\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 4 at dim 3 (got 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:315\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 315\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1821\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1822\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/accelerate/data_loader.py:448\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/trainer_utils.py:772\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[1;32m    771\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:45\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_call(features)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:735\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    732\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad(examples, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 735\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43m_torch_collate_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     }\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# If special token mask has been preprocessed, pop it from the dict.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m special_tokens_mask \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial_tokens_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:408\u001b[0m, in \u001b[0;36m_torch_collate_batch\u001b[0;34m(examples, tokenizer, pad_to_multiple_of)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# Tensorize if necessary.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 408\u001b[0m     examples \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(e, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m    410\u001b[0m length_of_first \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Check if padding is necessary.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.9/site-packages/transformers/data/data_collator.py:408\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# Tensorize if necessary.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 408\u001b[0m     examples \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m examples]\n\u001b[1;32m    410\u001b[0m length_of_first \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# Check if padding is necessary.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 3 (got 18)"
     ]
    }
   ],
   "source": [
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = \"mistralai-Code-Instruct-Finetune-test\" #Name of the model you will be pushing to huggingface model hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(new_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "merged_model= PeftModel.from_pretrained(base_model, new_model)\n",
    "merged_model= merged_model.merge_and_unload()\n",
    "\n",
    "# Save the merged model\n",
    "merged_model.save_pretrained(\"merged_model\",safe_serialization=True)\n",
    "tokenizer.save_pretrained(\"merged_model\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = create_datasets(tokenizer, train_dataset, test_dataset, valid_dataset, seq_length=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.push_to_hub(new_model, use_temp_dir=False, token='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')\n",
    "tokenizer.push_to_hub(new_model, use_temp_dir=False, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_merged(query: str, merged_model, tokenizer) -> str:\n",
    "  device = \"cuda:0\"\n",
    "\n",
    "  prompt_template = \"\"\"### Instruction:\n",
    "    You are medical expert, and medical data engineer with many years on working with complex medical receipt structure. \n",
    "    I need you parse, detect, recognize and convert following medical receipt OCR image result into structure medical receipt format. \n",
    "    the outout mus be a well-formed json object.```json\n",
    "\n",
    "    ### Input:\n",
    "    {query}\n",
    "\n",
    "    ### Output:\n",
    "    \"\"\"\n",
    "  prompt = prompt_template.format(query=query)\n",
    "\n",
    "  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "  model_inputs = encodeds.to(device)\n",
    "\n",
    "  generated_ids = merged_model.generate(**model_inputs, max_new_tokens=1000, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "  decoded = tokenizer.batch_decode(generated_ids)\n",
    "  return (decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querry = test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_completion_merged(query=str(querry), merged_model=merged_model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
