{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Từ đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (4.2.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.5)\n",
      "Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai==0.28) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from openai==0.28) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/huynv43/miniconda3/envs/myenv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(file_txt):\n",
    "    content_system =\"\"\"\n",
    "        You are an AI Assistant in the medical field. Your goal is to provide the Human with information extracted from the Human's prescription. Think step by step and never skip any step.\n",
    "        Please try to extract all data points. Do not add or omit any information. Don't include information that is not in the document in your answer, only return json format, no more conversation\n",
    "        This is content :\"\"\"\n",
    "    messages = [ {\"role\": \"system\", \"content\":\n",
    "              content_system} ]\n",
    "    with open(file_txt, 'r') as file:\n",
    "    # Read the entire contents of the file\n",
    "        content_user = file.read()\n",
    "    json_format = \"\"\"\n",
    "    And extract with the following format:\n",
    "    {\n",
    "        \"patient\": {\n",
    "            \"current_institute\": \"name of the hospital or clinic issuing the prescription\",\n",
    "            \"name\": \"patient full name\",\n",
    "            \"gender\": \"patient gender\",\n",
    "            \"birth\": \"date of birth\",\n",
    "            \"age\": \"patient age\",\n",
    "            \"address\": \"patient address\",\n",
    "            \"tel_customer\": \"patient phone number\",\n",
    "            \"id_bhyt\": \"health insurance card number\"\n",
    "        },\n",
    "        \"medical\": {\n",
    "            \"diagnosis\": \"diagnosis\",\n",
    "            \"date_in\": \"issued date\",\n",
    "            \"doctor_name\": \"doctor full name\"\n",
    "        },\n",
    "        \"drugs\": [{\n",
    "            \"drug_name\": \"drug name\",\n",
    "            \"drug_dose\": \"drug dosage, usage and instructions\",\n",
    "            \"drug_quantity\": \"drug duantity\"\n",
    "        }]\n",
    "    }\"\"\"\n",
    "    content_user = content_user + json_format\n",
    "    messages.append(\n",
    "    {\"role\": \"user\", \"content\": content_user})\n",
    "    chat = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "    reply = chat.choices[0].message.content\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20\n",
    "192\n",
    "214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Long_Chau_501',\n",
    " 'BV_TH_1022',\n",
    " 'Long_Chau_314',\n",
    " 'Long_Chau_385',\n",
    " 'Long_Chau_215',\n",
    " 'Long_Chau_120',\n",
    " 'Long_Chau_60',\n",
    " '20210503_205658408597',\n",
    " 'Long_Chau_412',\n",
    " 'Long_Chau_376',\n",
    " 'Long_Chau_63',\n",
    " 'Long_Chau_265',\n",
    " '20210503_205658397640',\n",
    " 'Long_Chau_209',\n",
    " 'Long_Chau_164',\n",
    " 'Long_Chau_193',\n",
    " 'Long_Chau_241',\n",
    " '20210503_205809228580',\n",
    " 'DK_GiaLam_1025',\n",
    " 'Long_Chau_153',\n",
    " 'Long_Chau_275',\n",
    " 'BV_TH_1002',\n",
    " 'Long_Chau_371',\n",
    " 'Long_Chau_295',\n",
    " 'Long_Chau_380',\n",
    " 'Long_Chau_502',\n",
    " 'Long_Chau_484',\n",
    " '20210503_205903110284',\n",
    " 'Long_Chau_351',\n",
    " 'BV_TH_1038',\n",
    " 'Long_Chau_47',\n",
    " 'Long_Chau_83',\n",
    " 'Long_Chau_57',\n",
    " 'Long_Chau_252',\n",
    " 'Long_Chau_410',\n",
    " 'Long_Chau_398',\n",
    " 'Long_Chau_454',\n",
    " '20210503_205809236617',\n",
    " 'Long_Chau_403',\n",
    " 'Long_Chau_448',\n",
    " 'Long_Chau_414',\n",
    " 'BV_TH_1005',\n",
    " 'Long_Chau_430',\n",
    " 'BV_TH_1009',\n",
    " 'Long_Chau_466',\n",
    " 'Long_Chau_408',\n",
    " 'Long_Chau_165',\n",
    " 'Long_Chau_106',\n",
    " 'Long_Chau_280',\n",
    " 'Long_Chau_463',\n",
    " 'Long_Chau_184',\n",
    " 'Long_Chau_39',\n",
    " 'BV_TH_1030',\n",
    " 'Long_Chau_224',\n",
    " '20210503_205658401786',\n",
    " 'Long_Chau_449',\n",
    " 'Long_Chau_32',\n",
    " 'Long_Chau_161',\n",
    " 'Long_Chau_360',\n",
    " 'BV_TH_1023',\n",
    " 'Long_Chau_368',\n",
    " 'Long_Chau_397',\n",
    " 'Long_Chau_269',\n",
    " 'Long_Chau_250',\n",
    " 'Long_Chau_251',\n",
    " 'Long_Chau_102',\n",
    " 'BV_TH_1006',\n",
    " 'Long_Chau_331',\n",
    " 'Long_Chau_330',\n",
    " 'Long_Chau_175',\n",
    " 'Long_Chau_126',\n",
    " 'Long_Chau_521',\n",
    " 'Long_Chau_46',\n",
    " '20210503_205809235716',\n",
    " 'Long_Chau_210',\n",
    " 'Long_Chau_262',\n",
    " 'Long_Chau_363',\n",
    " 'Long_Chau_464',\n",
    " 'BV_TH_1029',\n",
    " 'Long_Chau_87',\n",
    " 'Long_Chau_169',\n",
    " 'Long_Chau_27',\n",
    " 'Long_Chau_266',\n",
    " 'Long_Chau_248',\n",
    " 'Long_Chau_467',\n",
    " 'Long_Chau_468',\n",
    " 'Long_Chau_431',\n",
    " '20210503_205903110716',\n",
    " 'Long_Chau_415',\n",
    " 'Long_Chau_183',\n",
    " 'Long_Chau_406',\n",
    " 'Long_Chau_221',\n",
    " '20210503_205658404488',\n",
    " 'Long_Chau_114',\n",
    " 'Long_Chau_168',\n",
    " 'Long_Chau_238',\n",
    " 'Long_Chau_31',\n",
    " 'Long_Chau_160',\n",
    " 'Long_Chau_263',\n",
    " 'Long_Chau_357',\n",
    " 'Long_Chau_217',\n",
    " 'Long_Chau_270',\n",
    " 'Long_Chau_311',\n",
    " 'Long_Chau_326',\n",
    " '20210503_205658401338',\n",
    " 'BV_TH_1016',\n",
    " 'Long_Chau_459',\n",
    " 'Long_Chau_516',\n",
    " 'Long_Chau_182',\n",
    " 'Long_Chau_118',\n",
    " 'Long_Chau_419',\n",
    " 'Long_Chau_299',\n",
    " 'Long_Chau_496',\n",
    " 'Long_Chau_41',\n",
    " 'Long_Chau_306',\n",
    " 'Long_Chau_329',\n",
    " 'Long_Chau_422',\n",
    " 'Long_Chau_223',\n",
    " 'BV_TH_1034',\n",
    " 'Long_Chau_296',\n",
    " 'Long_Chau_526',\n",
    " 'Long_Chau_392',\n",
    " 'BV_TH_1019',\n",
    " 'Long_Chau_298',\n",
    " 'Long_Chau_346',\n",
    " 'Long_Chau_455',\n",
    " 'BV_TH_102',\n",
    " '20210503_205658399027',\n",
    " 'Long_Chau_99',\n",
    " 'Long_Chau_286',\n",
    " 'Long_Chau_328',\n",
    " 'Long_Chau_259',\n",
    " 'Long_Chau_37',\n",
    " 'Long_Chau_82',\n",
    " 'Long_Chau_234',\n",
    " 'Long_Chau_258',\n",
    " 'Long_Chau_50',\n",
    " 'Long_Chau_327',\n",
    " 'Long_Chau_513',\n",
    " 'Long_Chau_498',\n",
    " 'Long_Chau_382',\n",
    " 'Long_Chau_318',\n",
    " '20210503_205809230315',\n",
    " 'Long_Chau_373',\n",
    " 'Long_Chau_80',\n",
    " 'Long_Chau_500',\n",
    " '20210503_205903111701',\n",
    " 'Long_Chau_111',\n",
    " 'BV_TH_1017',\n",
    " 'Long_Chau_355',\n",
    " 'BV_TH_1027',\n",
    " 'Long_Chau_377',\n",
    " 'Long_Chau_40',\n",
    " 'Long_Chau_294',\n",
    " '20210503_205809227186',\n",
    " '20210503_205809229025',\n",
    " 'Long_Chau_76',\n",
    " 'Long_Chau_149',\n",
    " 'Long_Chau_214',\n",
    " 'Long_Chau_92',\n",
    " 'Long_Chau_510',\n",
    " 'Long_Chau_219',\n",
    " 'BV_TH_1031',\n",
    " 'Long_Chau_49',\n",
    " 'Long_Chau_192',\n",
    " 'Long_Chau_395',\n",
    " 'Long_Chau_206',\n",
    " 'Long_Chau_396',\n",
    " 'Long_Chau_480',\n",
    " '20210503_205658407631',\n",
    " 'Long_Chau_190',\n",
    " 'Long_Chau_509',\n",
    " 'Long_Chau_43',\n",
    " 'BV_TH_1000',\n",
    " 'Long_Chau_119',\n",
    " 'BV_TH_1036',\n",
    " 'Long_Chau_291',\n",
    " 'Long_Chau_469',\n",
    " 'Long_Chau_220',\n",
    " 'Long_Chau_312',\n",
    " 'Long_Chau_388',\n",
    " 'Long_Chau_488',\n",
    " 'Long_Chau_130',\n",
    " 'Long_Chau_163',\n",
    " '20210503_205658410902',\n",
    " 'BV_TH_1004',\n",
    " 'Long_Chau_393',\n",
    " 'Long_Chau_332',\n",
    " 'Long_Chau_307',\n",
    " 'Long_Chau_372',\n",
    " '20210503_205658402270',\n",
    " 'Long_Chau_525',\n",
    " 'Long_Chau_75',\n",
    " 'Long_Chau_366',\n",
    " 'Long_Chau_279',\n",
    " 'Long_Chau_240',\n",
    " 'Long_Chau_336',\n",
    " 'Long_Chau_297',\n",
    " 'BV_TH_1011',\n",
    " 'Long_Chau_204',\n",
    " '20210503_205658406224',\n",
    " 'Long_Chau_170',\n",
    " 'Long_Chau_452',\n",
    " '20210503_205809236159',\n",
    " 'DK_GiaLam_100',\n",
    " '20210503_205809227655',\n",
    " 'Long_Chau_277',\n",
    " 'Long_Chau_285',\n",
    " 'BV_TH_1037',\n",
    " '20210503_205903109806',\n",
    " 'Long_Chau_487',\n",
    " 'BV_TH_1024',\n",
    " 'Long_Chau_370',\n",
    " 'Long_Chau_242',\n",
    " 'Long_Chau_322',\n",
    " 'Long_Chau_229',\n",
    " 'Long_Chau_113',\n",
    " 'Long_Chau_367',\n",
    " 'Long_Chau_490',\n",
    " 'Long_Chau_274',\n",
    " 'Long_Chau_443',\n",
    " 'Long_Chau_432',\n",
    " 'Long_Chau_211',\n",
    " '20210503_205658403116',\n",
    " 'Long_Chau_172',\n",
    " 'BV_TH_1013',\n",
    " 'Long_Chau_486',\n",
    " 'Long_Chau_232',\n",
    " 'Long_Chau_485',\n",
    " 'BV_TH_1001',\n",
    " 'Long_Chau_147',\n",
    " 'Long_Chau_317',\n",
    " 'Long_Chau_261',\n",
    " 'Long_Chau_150',\n",
    " '20210503_205809231206',\n",
    " 'Long_Chau_421',\n",
    " 'Long_Chau_462',\n",
    " 'Long_Chau_507',\n",
    " 'Long_Chau_166',\n",
    " 'Long_Chau_409',\n",
    " 'Long_Chau_361',\n",
    " 'Long_Chau_243',\n",
    " 'Long_Chau_94',\n",
    " 'Long_Chau_356',\n",
    " 'Long_Chau_413',\n",
    " 'Long_Chau_70',\n",
    " 'Long_Chau_479',\n",
    " 'Long_Chau_202',\n",
    " 'Long_Chau_405']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder_with_api(input_folder, output_folder, text_files = names):\n",
    "    # text_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.txt')]\n",
    "    text_files = [text_file + '.txt' for text_file in text_files]\n",
    "    for text_file in tqdm(text_files):\n",
    "        print(text_file)\n",
    "        # Construct the full path of the input text file\n",
    "        input_file_path = os.path.join(input_folder, text_file)\n",
    "        result = call_openai(input_file_path)\n",
    "        output_json_file = os.path.splitext(text_file)[0] + '.json'\n",
    "        output_json_file_path = os.path.join(output_folder, output_json_file)\n",
    "        with open(output_json_file_path, 'w') as json_file:\n",
    "            json.dump(result, json_file, indent=4)\n",
    "        time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_folder_with_api(\"/home/huynv43/langchain_rag/data/txt\",\"/home/huynv43/langchain_rag/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    try:\n",
    "        # List all files in the folder\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        \n",
    "        # Count the number of files\n",
    "        file_count = len(files)\n",
    "        \n",
    "        return file_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error counting files in folder: {str(e)}\")\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_files_in_folder(\"/home/huynv43/langchain_rag/json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
